{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Images.shape()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport cv2\nfrom PIL import Image as pil\n#import tensorflow.keras.layers as Layers\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import utils as np_utils\nfrom keras.utils import to_categorical\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_df = pd.read_csv('../input/shopee-product-detection-open/train.csv')\ntest_df = pd.read_csv('../input/shopee-product-detection-open/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dir = '../input/shopee-product-detection-open/train/train/train/'\nImages = []\nLabels = []\n#n = 1500 # No. of images to read for each category  #  Total no. of images = (n*42)\n\nfor labels in os.listdir(dir):\n    #i = 0\n    for file in os.listdir(dir + labels):\n        #if i > n-1:\n        #    break\n        path = dir + labels + '/' + file\n        \n        # Reading image as grayscale and resizing\n        image = cv2.imread(path,0)\n        image = cv2.resize(image,(100,100))\n        image = np.expand_dims(image, 2)\n        #i += 1\n        \n        Images.append(image)\n        Labels.append(labels)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using ImageDataGenerator","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_dir = '../input/shopee-product-detection-open/train/train/train'\nbatch_size = 32\n\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   rotation_range=45,\n                                   width_shift_range=.15,\n                                   height_shift_range=.15,\n                                   horizontal_flip=True,\n                                   zoom_range=0.5,\n                                   validation_split=0.2) # set validation split\n\ntrain_generator = train_datagen.flow_from_directory(train_data_dir,\n                                                    target_size=(50, 50),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    subset='training') # set as training data\n\nvalidation_generator = train_datagen.flow_from_directory(train_data_dir, # same directory as training data\n                                                         target_size=(50, 50),\n                                                         batch_size=batch_size,\n                                                         class_mode='categorical',\n                                                         subset='validation') # set as validation data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_list = [Images,Labels]\n\n# Converting Images and Labels to array\nImages_array = np.array(Images)\nLabels_array = np.array(Labels)\n\n# Rescaling\nImages_array = Images_array/255\n\n# Split Train and Test Data\nX_train, X_test, y_train, y_test = train_test_split(Images_array, \n                                                    Labels_array, \n                                                    random_state=42, \n                                                    test_size=0.3, \n                                                    stratify=Labels_array, \n                                                    shuffle=True)\n\n# One-hot encoding column\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compiling Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\n# Adding Layers to Model\nmodel.add(Conv2D(128, kernel_size=3, activation=\"relu\", input_shape=(100,100,1)))\nmodel.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nDropout(.2)\nmodel.add(Conv2D(256, kernel_size=3, activation=\"relu\"))\nmodel.add(Conv2D(256, kernel_size=3, activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nDropout(.2)\nmodel.add(Conv2D(512, kernel_size=3, activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nDropout(.2)\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(42, activation='softmax'))\n\n# Compiling Model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='Adam', \n              metrics=['accuracy'])\n\n#model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding weights","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\n# Adding weights to categories with lesser data\ny_integers = np.argmax(y_train, axis=1)\nclass_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\nd_class_weights = dict(enumerate(class_weights))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model fit","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_generator, \n          epochs=6, \n          validation_data=validation_generator, \n          class_weight=d_class_weights)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Test images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dir = '../input/shopee-product-detection-open/test/test/test/'\nImages_name = []\nImages_test_array = []\n\n#n = 100 # No. of test images to read for test\n\ni = 0\nfor file in test_df['filename']:\n    #if i > n-1 :\n    #    break\n    \n    path = dir + '/' +file\n    image = cv2.imread(path,0)\n    image = cv2.resize(image,(50,50))\n    image = np.expand_dims(image, 2)\n    \n    i += 1\n    Images_name.append(file)\n    Images_test_array.append(image)\n\n# Rescaling \nImages_test_array = np.array(Images_test_array)/255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model predict","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_category = model.predict_classes(Images_test_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Output Dataframe answer as CSV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ans_df = pd.DataFrame({'filename':Images_name, 'category': pred_category})\nans_df['category'] = ans_df['category'].astype(str)\nans_df.to_csv(\"/kaggle/working/submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}